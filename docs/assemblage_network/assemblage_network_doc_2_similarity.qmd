---
title: "Similarity Measures for Graph Adjacency with Sets"
author: "James Scott Cardinal"
date: 10/14/2021
format: html
editor: visual
editor_options: 
  chunk_output_type: inline
bibliography: references.bib
---

![](archaeo_DS_mine.png)

In my last installment ([Part I](https://medium.com/p/648a2f20d389)), I introduced you to a bit about the process of analyzing an archaeological site with data science. I talked about the frustratingly complex nature of "Old Things in Space" and how the network of artifacts and locations constitute a bipartite graph.

As we worked through the process of creating a two-mode graph and projecting it into its constituent one-mode graphs, however, we ended on something of a cliff-hanger... *everything* ended up connected to *everything else*!

Well, sort of. I have to confess that I intentionally lead you down a primrose path straight into a carefully crafted cul-de-sac. All part of my cunning plan, of course, to get to the much more interesting topic of thinking about just what it means for two things to be "similar" and similarity metrics for *sets.*

In my defense, I did briefly mention that `igraph` doesn't really have the best of tools to actually *do* much of anything interesting with bipartite graphs. The problem is that the method it uses in its `bipartite_projection` simply sums the pairwise occurrences in the incidence matrix. That, as it turns out, is less than useful in a lot of cases.

Instead, we need to explore some more robust methods for evaluating *similarity* between sets. Unlike numerical methods of calculating correlation or distance, there are some conceptual peculiarities when comparing correspondence and similarity between sets that need to be considered. In this article, we'll look at some of the most commonly used set-based similarity metrics and reason through *how* to choose the appropriate metric for our goals.

For those just joining in, this is the Part II of a series in archaeological data science covering:

-   [Part I](https://medium.com/p/648a2f20d389) -- Creating and exploring bipartite and one-mode graphs,

-   Part II -- Similarity measures for sets and graph adjacency,

-   Part III -- Graph structure and community detection methods,

-   Part IV -- Geo-spatial networks

I'll continue using R for the coding, but again all of this could be done with Python just as easily.

# Introduction

Before we get into the weeds of metrics, methods, and combinatorics (i.e., the mathematics of *sets*) let's stop to think for a moment about just what we mean when we say that two things are *similar*.

In general, we refer to things as *similar* when they are neither the quite the same nor are they entirely different. Similar things are alike-*ish*. It means that some measure of shared features or attributes is suggesting *association* but not necessarily *commonality* or *identity*. It denotes a resemblance or correspondence, but there's a certain fuzziness about it -- i.e., similarity implies a subjective or qualitative assessment.

Our goal, then, is twofold. Firstly, we need to determine what set similarity metric most closely reflects the *relationship* between set elements. Secondly, we have to determine an appropriate method for determining the *threshold* of similarity between those entities. In other words, we need to choose our criteria for *resemblance* and set the *limits* of what is (or isn't) considered similar between our sets.

## Sets and Similarity

Unlike real-valued vector spaces in which distance or similarity can be readily calculated, sets consist of an un-ordered collection of unique members or elements. Those member elements can be anything -- e.g., numbers, letters, words, objects, categories -- so there isn't always an obvious numerical solution such as vector norms or coordinates that can be used for comparison of elements.

Instead, we have to compare the membership of elements between sets. More specifically, we compare the size or *cardinality* of certain attributes of or operation on the sets such as their intersections and unions. Luckily, there are numerous metrics available for comparing similarity between sets. For our purposes, I will discuss only a few that are most common:

-   Overlap or Szymkiewicz-Simpson coefficient
-   Jaccard similarity coefficient (a.k.a. Tanimoto coefficient)
-   SÃ¸rensen--Dice coefficient

Each of these similarity measures was derived specifically to address the peculiarities of dealing with sets. The difference between them is just the way in which they weight common elements (i.e., intersections) against differences.

It is important to consider, however, exactly what relationships between sets you are trying to capture before choosing a method. If your samples all contain approximately the same number of elements, you might choose differently than if each sample has widely different numbers of members. How likely are complete subsets, and are those important to capture? Are differences more imporant than commonalities, or the other way around?

As with any data analysis, it's necessary to explicitly consider your *methodology* as well as your methods. The rationale and justification for the selection of methods is a critical part of the process. That is, after all, why we call it data *science*.

# Bipartite Projections by Similarity
